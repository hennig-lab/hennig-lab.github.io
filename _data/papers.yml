  # -
  #   title: ""
  #   authors: ""
  #   journal: ""
  #   volume: ""
  #   year: 2024
  #   paper_url: ""
  #   code_url: ""
  #   short_name: ""
  #   imagetype: png
  #   briefly: ""
  #   summary: ""
2024:
  -
    title: "Learning alters neural activity to simultaneously support memory and action"
    authors: "Losey DM, <b>Hennig JA</b>+, Oby ER+, Golub MD, Sadtler PT, Quick KM, Ryu SI, Tyler-Kabara EC, Batista AP*, Yu BM*, Chase SM*"
    journal: "Current Biology"
    volume: "34 (7): 1519-1531"
    year: 2024
    paper_url: "https://www.sciencedirect.com/science/article/pii/S0960982224002987?dgcid=author"
    code_url: ""
    short_name: "Losey2024"
    imagetype: png
    press_url: "https://engineering.cmu.edu/news-events/news/2024/03/21-honoring-cohon.html"
    briefly: "How do we learn new behaviors without disrupting previously learned ones? Using a brain-computer interface (BCI) paradigm, we found that learning a new task altered the neural activity used to perform familiar tasks. This \"memory trace\" did not interfere with the performance of familiar tasks, suggesting a possible mechanism for how we learn new behaviors without impacting previously learned ones."
    summary: "How are we able to learn new behaviors without disrupting previously learned ones? To understand how the brain achieves this, we used a brain-computer interface (BCI) learning paradigm, which enables us to detect the presence of a memory of one behavior while performing another. We found that learning to use a new BCI map altered the neural activity that monkeys produced when they returned to using a familiar BCI map, in a way that was specific to the learning experience. That is, learning left a “memory trace.” This memory trace co-existed with proficient performance under the familiar map, primarily by altering dimensions of neural activity that did not impact behavior. Such a memory trace could provide the neural underpinning for the joint learning of multiple motor behaviors without interference."
  -
    title: "The role of prospective contingency in the control of behavior and dopamine signals during associative learning"
    authors: "Qian, L*, Burrell, M*, <b>Hennig, JA</b>, Matias, S, Murthy, VN, Gershman, SJ, & Uchida, N"
    journal: "bioRxiv"
    volume: ""
    year: 2024
    paper_url: "https://www.biorxiv.org/content/10.1101/2024.02.05.578961v1.abstract"
    code_url: ""
    short_name: ""
    imagetype: png
    briefly: ""
    summary: ""
2023:
  -
    title: "Emergence of belief-like representations through reinforcement learning"
    authors: "<b>Hennig JA</b>, Romero-Pinto SA, Yamaguchi T, Linderman SW, Uchida N, Gershman SJ"
    journal: "PLOS Computational Biology"
    volume: "19 (9): e1011067"
    year: 2023
    paper_url: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011067
    code_url: https://github.com/mobeets/value-rnn-beliefs
    short_name: Hennig2023
    imagetype: png
    briefly: "Animals are thought to predict rewards using reinforcement learning (RL). In environments with hidden states, animals may require \"beliefs,\" or probabilistic estimates of the hidden states. We show that such belief-like representations emerge in recurrent neural networks (RNN) trained to perform RL in environments with hidden states."
    summary: "To behave adaptively, animals must learn to predict future reward, or value. To do this, animals are thought to learn reward predictions using reinforcement learning. However, in contrast to classical models, animals must learn to estimate value using only incomplete state information. Previous work suggests that animals estimate value in partially observable tasks by first forming “beliefs”—optimal Bayesian estimates of the hidden states in the task. Although this is one way to solve the problem of partial observability, it is not the only way, nor is it the most computationally scalable solution in complex, real-world environments. Here we show that a recurrent neural network (RNN) can learn to estimate value directly from observations, generating reward prediction errors that resemble those observed experimentally, without any explicit objective of estimating beliefs. We integrate statistical, functional, and dynamical systems perspectives on beliefs to show that the RNN’s learned representation encodes belief information, but only when the RNN’s capacity is sufficiently large. These results illustrate how animals can estimate value in tasks without explicitly estimating beliefs, yielding a representation useful for systems with limited capacity."
2021:
  -
    title: "How learning unfolds in the brain: toward an optimization view"
    authors: "<b>Hennig JA</b>, Oby ER, Losey DM, Batista AP*, Yu BM*, Chase SM*"
    journal: "Neuron"
    volume: "109 (23), 3720-3735"
    year: 2021
    paper_url: https://www.cell.com/neuron/fulltext/S0896-6273(21)00677-2
    short_name: Hennig2021b
    imagetype: png
    briefly: "In this perspective, we consider the idea that learning in the brain can be described in terms of optimization, similar to learning in artificial neural networks (ANNs). We highlight three key features of how neural population changes with learning that differ from ANNs, suggesting refinements to this optimization view."
    summary: "How do changes in the brain lead to learning? To answer this question, consider an artificial neural network (ANN), where learning proceeds by optimizing a given objective or cost function. This “optimization framework” may provide new insights into how the brain learns, as many idiosyncratic features of neural activity can be recapitulated by an ANN trained to perform the same task. Nevertheless, there are key features of how neural population activity changes throughout learning that cannot be readily explained in terms of optimization and are not typically features of ANNs. Here we detail three of these features: (1) the inflexibility of neural variability throughout learning, (2) the use of multiple learning processes even during simple tasks, and (3) the presence of large task-nonspecific activity changes. We propose that understanding the role of these features in the brain will be key to describing biological learning using an optimization framework."
  -
    title: "Learning is shaped by abrupt changes in neural engagement"
    authors: "<b>Hennig JA</b>, Oby ER, Golub MD, Bahureksa LA, Sadtler PT, Quick KM, Ryu SI, Tyler-Kabara EC, Batista AP*, Chase SM*, Yu BM*"
    journal: "Nature Neuroscience"
    volume: "24 (5), 727-736"
    year: 2021
    paper_url: "https://www.nature.com/articles/s41593-021-00822-8"
    code_url: 'https://github.com/mobeets/neural-engagement'
    press_url: 'https://engineering.cmu.edu/news-events/news/2021/03/29-engagement-learning.html'
    short_name: Hennig2021
    imagetype: gif
    briefly: "We identified large fluctuations in neural population activity in motor cortex (M1) indicative of arousal-like internal state changes. These changes in neural activity helped to explain why animals learned some tasks more quickly than others."
    summary: "Internal states such as arousal, attention, and motivation are known to modulate brain-wide neural activity, but how these processes interact with learning is not well understood. During learning, the brain must modify the neural activity it produces to improve behavioral performance. How do internal states affect the evolution of this learning process? Using a brain-computer interface (BCI) learning paradigm in non-human primates, we identified large fluctuations in neural population activity in motor cortex (M1) indicative of arousal-like internal state changes. These fluctuations drove population activity along dimensions we term neural engagement axes. Neural engagement increased abruptly at the start of learning, and then gradually retreated. In a BCI, the causal relationship between neural activity and behavior is known. This allowed us to understand how these changes impacted behavioral performance for different task goals. We found that neural engagement interacted with learning, helping to explain why animals learned some task goals more quickly than others."
2020:
  -
    title: "Intracortical Brain-Machine Interfaces"
    authors: "Oby ER, <b>Hennig JA</b>, Batista AP*, Yu BM*, Chase SM*"
    journal: "Neural Engineering, 3rd Edition"
    volume: "185-221"
    year: 2020
    paper_url: "https://link.springer.com/chapter/10.1007/978-3-030-43395-6_5"
    short_name: Oby2020
    imagetype: png
    briefly: "A brain–machine interface (BMI) directly connects the brain to the external world, translating a user's internal motor commands into action. In this chapter, we discuss the four basic components of an intracortical BMI: an intracortical neural recording, a decoding algorithm, an output device, and sensory feedback."
    summary: ""
2019:
  -
    title: "New neural activity patterns emerge with long-term learning"
    authors: "Oby ER, Golub MD, <b>Hennig JA</b>, Degenhart AD, Tyler-Kabara EC, Yu BM*, Chase SM*, Batista AP*"
    journal: "Proceedings of the National Academy of Sciences"
    volume: "116 (30), 15210-15215"
    year: 2019
    paper_url: https://www.pnas.org/content/116/30/15210.short
    short_name: Oby2019
    imagetype: png
    briefly: "We establish that new neural activity patterns emerge with learning, providing evidence that the formation of new patterns of neural population activity can underlie the learning of new skills."
    summary: "Learning has been associated with changes in the brain at every level of organization. However, it remains difficult to establish a causal link between specific changes in the brain and new behavioral abilities. We establish that new neural activity patterns emerge with learning. We demonstrate that these new neural activity patterns cause the new behavior. Thus, the formation of new patterns of neural population activity can underlie the learning of new skills."
2018: 
  -
    title: "Constraints on neural redundancy"
    authors: "<b>Hennig JA</b>, Golub MD, Lund PJ, Sadtler PT, Oby ER, Quick KM, Ryu SI, Tyler-Kabara EC, Batista AP*, Yu BM*, Chase SM*"
    journal: "eLife"
    volume: "7, e36774"
    year: 2018
    paper_url: https://elifesciences.org/articles/36774
    short_name: Hennig2018
    imagetype: png
    code_url: https://github.com/mobeets/neural-redundancy-elife2018
    briefly: "Millions of neurons in the brain control the activity of tens of muscles in the arm, meaning neural activity is redundant. We compared various hypotheses for how the brain deals with this redundancy by recording in primary motor cortex while subjects performed a brain-computer interface task."
    summary: "Millions of neurons drive the activity of hundreds of muscles, meaning many different neural population activity patterns could generate the same movement. Studies have suggested that these redundant (i.e. behaviorally equivalent) activity patterns may be beneficial for neural computation. However, it is unknown what constraints may limit the selection of different redundant activity patterns. We leveraged a brain-computer interface, allowing us to define precisely which neural activity patterns were redundant. Rhesus monkeys made cursor movements by modulating neural activity in primary motor cortex. We attempted to predict the observed distribution of redundant neural activity. Principles inspired by work on muscular redundancy did not accurately predict these distributions. Surprisingly, the distributions of redundant neural activity and task-relevant activity were coupled, which enabled accurate predictions of the distributions of redundant activity. This suggests limits on the extent to which redundancy may be exploited by the brain for computation."
2017:
  -
    title: "A classifying variational autoencoder with application to polyphonic music generation"
    authors: "<b>Hennig JA</b>, Umakantha A, Williamson RC"
    journal: "arXiv"
    volume: "arXiv:1711.07050"
    year: 2017
    paper_url: https://arxiv.org/abs/1711.07050
    short_name: Hennig2017
    imagetype: png
    code_url: https://github.com/mobeets/vrnn
    demo: http://neural-synth.herokuapp.com/
    briefly: "We augment a neural network known as a variational autoencoder (VAE) to classify the observed data while also learning its latent representation. We show that when this network is combined with an LSTM and used to generate music, the network plays fewer incorrect notes than a standard VAE+LSTM."
    summary: "The variational autoencoder (VAE) is a popular probabilistic generative model. However, one shortcoming of VAEs is that the latent variables cannot be discrete, which makes it difficult to generate data from different modes of a distribution. Here, we propose an extension of the VAE framework that incorporates a classifier to infer the discrete class of the modeled data. To model sequential data, we can combine our Classifying VAE with a recurrent neural network such as an LSTM. We apply this model to algorithmic music generation, where our model learns to generate musical sequences in different keys. Most previous work in this area avoids modeling key by transposing data into only one or two keys, as opposed to the 10+ different keys in the original music. We show that our Classifying VAE and Classifying VAE+LSTM models outperform the corresponding non-classifying models in generating musical samples that stay in key. This benefit is especially apparent when trained on untransposed music data in the original keys."
2015:
  -
    title: "A distinct mechanism of temporal integration for motion through depth"
    authors: "Katz LN, <b>Hennig JA</b>, Cormack LK, Huk AC"
    journal: "Journal of Neuroscience"
    volume: "35 (28), 10212-10216"
    year: 2015
    paper_url: https://www.jneurosci.org/content/35/28/10212.short
    short_name: Katz2015
    imagetype: png
    briefly: "We compare the time-varying improvements in sensitivity during motion discrimination tasks in 2D and 3D, and find that the two are remarkably similar, however with a lower signal-to-noise ratio in 3D."
    summary: "Temporal integration of visual motion has been studied extensively within the frontoparallel plane (i.e., 2D). However, the majority of motion occurs within a 3D environment, and it is unknown whether the principles from 2D motion processing generalize to more realistic 3D motion. We therefore characterized and compared temporal integration underlying 2D (left/right) and 3D (toward/away) direction discrimination in human observers, varying motion coherence across a range of viewing durations. The resulting discrimination-versus-duration functions followed three stages, as follows: (1) a steep improvement during the first ∼150 ms, likely reflecting early sensory processing; (2) a subsequent, more gradual benefit of increasing duration over several hundreds of milliseconds, consistent with some form of temporal integration underlying decision formation; and (3) a final stage in which performance ceased to improve with duration over ∼1 s, which is consistent with an upper limit on integration. As previously found, improvements in 2D direction discrimination with time were consistent with near-perfect integration. In contrast, 3D motion sensitivity was lower overall and exhibited a substantial departure from perfect integration. These results confirm that there are overall differences in sensitivity for 2D and 3D motion that are consistent with a sensory difference between binocular and dichoptic sensory mechanisms. They also reveal a difference at the integration stage, in which 3D motion is not accumulated as perfectly as in the 2D motion model system."
2013:
  -
    title: "Signal multiplexing and single-neuron computations in lateral intraparietal area during decision-making"
    authors: "Meister MLR, <b>Hennig JA</b>, Huk AC"
    journal: "Journal of Neuroscience"
    volume: "33 (6), 2254-2267"
    year: 2013
    paper_url: https://www.jneurosci.org/content/33/6/2254.short
    short_name: Meister2013
    imagetype: png
    briefly: "We show that cells in the lateral intraparietal area (LIP) have firing activity that simultaneously carries decision signals and decision-irrelevant sensory signals. We conclude that LIP cells show a broader range of response motifs than previously considered."
    summary: "Previous work has revealed a remarkably direct neural correlate of decisions in the lateral intraparietal area (LIP). Specifically, firing rate has been observed to ramp up or down in a manner resembling the accumulation of evidence for a perceptual decision reported by making a saccade into (or away from) the neuron's response field (RF). However, this link between LIP response and decision formation emerged from studies where a saccadic target was always stimulating the RF during decisions, and where the neural correlate was the averaged activity of a restricted sample of neurons. Because LIP cells are (1) highly responsive to the presence of a visual stimulus in the RF, (2) heterogeneous, and (3) not clearly anatomically segregated from large numbers of neurons that fail selection criteria, the underlying neuronal computations are potentially obscured. To address this, we recorded single neuron spiking activity in LIP during a well-studied moving-dot direction–discrimination task and manipulated whether a saccade target was present in the RF during decision-making. We also recorded from a broad sample of LIP neurons, including ones conventionally excluded in prior studies. Our results show that cells multiplex decision signals with decision-irrelevant visual signals. We also observed disparate, repeating response “motifs” across neurons that, when averaged together, resemble traditional ramping decision signals. In sum, neural responses in LIP simultaneously carry decision signals and decision-irrelevant sensory signals while exhibiting diverse dynamics that reveal a broader range of neural computations than previously entertained."
